# Checklist de Tests pour la D√©mo Finale

## Vue d'ensemble
Cette checklist contient tous les tests √† effectuer pour d√©montrer le fonctionnement de la stack de s√©curit√© Kubernetes.

## üìö Documentation compl√©mentaire
- **[DASHBOARDS_GUIDE.md](./DASHBOARDS_GUIDE.md)** : Guide complet pour configurer et interpr√©ter les dashboards Kibana et Grafana
- **[CREDENTIALS.md](./CREDENTIALS.md)** : Toutes les commandes pour r√©cup√©rer les credentials des services

---

## 1. Tests Trivy - Vuln√©rabilit√©s

### Test 1.1: D√©ploiement d'une image vuln√©rable
**Objectif:** V√©rifier que Trivy d√©tecte les vuln√©rabilit√©s et les exporte vers Elasticsearch/Kibana

**Commandes:**
```bash
# D√©ployer une image vuln√©rable (Alpine 3.12)
kubectl run vulnerable-test -n default --image=alpine:3.12 --command -- sleep 3600

# Attendre 2-3 minutes pour le scan automatique
sleep 180

# V√©rifier le rapport de vuln√©rabilit√©s
kubectl get vulnerabilityreports -n default | grep vulnerable-test

# Voir le r√©sum√© des vuln√©rabilit√©s
kubectl get vulnerabilityreport -n default -l trivy-operator.resource.name=vulnerable-test -o jsonpath='{.items[0].report.summary}' | jq

# Forcer l'export vers Elasticsearch
kubectl create job -n trivy-system trivy-export-demo --from=cronjob/trivy-exporter

# Attendre l'export (30 secondes)
sleep 30

# V√©rifier les logs
kubectl logs -n trivy-system job/trivy-export-demo
```

**V√©rification dans Kibana:**
1. Ouvrir Kibana: `kubectl port-forward -n security-siem svc/kibana-kibana 5601:5601`
2. Aller dans Analytics ‚Üí Discover
3. S√©lectionner le data view "Trivy Vulnerabilities"
4. Chercher: `namespace: "default" AND report_name: *vulnerable-test*`
5. V√©rifier la pr√©sence de vuln√©rabilit√©s CRITICAL et HIGH

**Temps estim√©:** 3-4 minutes

**Cleanup:**
```bash
kubectl delete pod vulnerable-test -n default
kubectl delete job trivy-export-demo -n trivy-system
```

---

### Test 1.2: V√©rification des dashboards Grafana
**Objectif:** Visualiser les m√©triques Trivy dans Grafana

**Commandes:**
```bash
# Port-forward Grafana
kubectl port-forward -n monitoring svc/prometheus-grafana 3000:80
```

**V√©rification:**
1. Ouvrir http://localhost:3000
2. Login avec admin/prom-operator
3. Chercher le dashboard Trivy
4. V√©rifier les m√©triques: nombre de vuln√©rabilit√©s par s√©v√©rit√©, par namespace, etc.

**Temps estim√©:** 2 minutes

---

## 2. Tests Gatekeeper - Policy Enforcement

### Test 2.1: Bloquer un pod sans labels requis
**Objectif:** V√©rifier que Gatekeeper bloque les d√©ploiements non conformes

**Commandes:**
```bash
# Tenter de cr√©er un pod sans labels (devrait √™tre bloqu√©)
kubectl run test-no-labels --image=nginx

# La commande devrait √©chouer avec un message de Gatekeeper
```

**R√©sultat attendu:** Rejet avec message explicatif

**Temps estim√©:** 1 minute

---

### Test 2.2: Bloquer une image non s√©curis√©e
**Objectif:** V√©rifier que Gatekeeper bloque les images de registres non autoris√©s

**Commandes:**
```bash
# Tenter d'utiliser une image non approuv√©e
kubectl run test-bad-registry --image=docker.io/nginx

# Devrait √™tre bloqu√© si la policy de registre approuv√© est active
```

**R√©sultat attendu:** Rejet ou acceptation selon les policies configur√©es

**Temps estim√©:** 1 minute

---

## 3. Tests Falco - Runtime Security

### Test 3.1: D√©tection de shell interactif dans un conteneur
**Objectif:** V√©rifier que Falco d√©tecte un shell interactif (comportement suspect)

**Commandes:**
```bash
# Cr√©er un pod de test
kubectl run falco-test --image=nginx

# Attendre que le pod d√©marre
kubectl wait --for=condition=ready pod/falco-test --timeout=60s

# Ex√©cuter un shell interactif (comportement suspect)
kubectl exec -it falco-test -- /bin/bash
# Taper quelques commandes puis exit

# V√©rifier les logs Falco
kubectl logs -n security-detection daemonset/falco | grep -i "shell"
```

**R√©sultat attendu:** Alerte Falco d√©tectant le shell interactif

**Temps estim√©:** 2 minutes

**Cleanup:**
```bash
kubectl delete pod falco-test
```

---

### Test 3.2: D√©tection d'√©criture dans /etc
**Objectif:** V√©rifier que Falco d√©tecte les modifications suspectes dans /etc

**Commandes:**
```bash
# Cr√©er un pod
kubectl run falco-test-etc --image=nginx

# Modifier un fichier dans /etc (comportement suspect)
kubectl exec falco-test-etc -- sh -c "echo 'test' >> /etc/passwd"

# V√©rifier les logs Falco
kubectl logs -n security-detection daemonset/falco | grep -i "etc"
```

**R√©sultat attendu:** Alerte Falco sur modification de /etc

**Temps estim√©:** 2 minutes

**Cleanup:**
```bash
kubectl delete pod falco-test-etc
```

---

### Test 3.3: V√©rification des alertes dans Falcosidekick UI et Kibana
**Objectif:** V√©rifier que les alertes Falco sont visibles dans les deux interfaces (temps r√©el + SIEM)

**Partie A: Falcosidekick UI (Interface temps r√©el)**

**Commandes:**
```bash
# Ouvrir l'interface Falcosidekick UI
kubectl port-forward -n security-detection svc/falco-falcosidekick-ui 2802:2802
```

**V√©rification dans le navigateur:**
1. Ouvrir http://localhost:2802
2. Login avec:
   - Username: `admin`
   - Password: `admin`
3. V√©rifier que des alertes sont pr√©sentes dans l'interface
4. Tester les filtres par Priority (Critical, Warning, Notice)
5. Tester les filtres par Rule

**G√©n√©rer une alerte de test:**
```bash
# Dans un autre terminal
kubectl run test-falco-alert --image=nginx
kubectl exec test-falco-alert -- /bin/bash -c "ls /etc"
kubectl delete pod test-falco-alert
```

**R√©sultat attendu:** L'alerte appara√Æt dans Falcosidekick UI en quelques secondes

---

**Partie B: Kibana (Analyse SIEM)**

**Commandes:**
```bash
# Ouvrir Kibana
kubectl port-forward -n security-siem svc/kibana-kibana 5601:5601
```

**V√©rification dans Kibana:**
1. Ouvrir http://localhost:5601
2. Login avec:
   - Username: `elastic`
   - Password: (obtenir avec `kubectl get secret -n security-siem elasticsearch-master-credentials -o jsonpath='{.data.password}' | base64 -d`)
3. Cr√©er le Data View si pas encore fait:
   - Stack Management ‚Üí Data Views
   - Create data view
   - Name: `Falco Alerts`
   - Index pattern: `falco-*`
   - Timestamp field: `time`
   - Save
4. Analytics ‚Üí Discover ‚Üí S√©lectionner "Falco Alerts"
5. Ajuster la plage de temps (Last 24 hours ou plus)
6. V√©rifier la pr√©sence d'alertes

**V√©rifier le nombre d'alertes dans Elasticsearch:**
```bash
ELASTIC_PASSWORD=$(kubectl get secret -n security-siem elasticsearch-master-credentials -o jsonpath='{.data.password}' | base64 -d)
POD=$(kubectl get pod -n security-siem -l app=elasticsearch-master -o jsonpath='{.items[0].metadata.name}')
kubectl exec -n security-siem $POD -- curl -k -s -u "elastic:$ELASTIC_PASSWORD" "https://localhost:9200/falco-*/_count" | jq
```

**R√©sultat attendu:**
- Count > 0 dans Elasticsearch
- Alertes visibles dans Kibana Discover
- Champs disponibles: output, priority, rule, output_fields.*, hostname

**Exemples de recherches dans Kibana:**
```
priority: "Critical"
rule: "Terminal shell in container"
output_fields.k8s_ns_name: "default"
```

**Temps estim√©:** 5 minutes

---

### Test 3.4: V√©rification des m√©triques Falco dans Grafana
**Objectif:** V√©rifier que les m√©triques Falco sont collect√©es par Prometheus et visualisables dans Grafana

**Partie A: Acc√®s au dashboard Grafana Falco**

**Commandes:**
```bash
# Ouvrir Grafana
kubectl port-forward -n security-siem svc/prometheus-grafana 3000:80
```

**V√©rification dans le navigateur:**
1. Ouvrir http://localhost:3000
2. Login avec:
   - Username: `admin`
   - Password: (obtenir avec `kubectl get secret -n security-siem prometheus-grafana -o jsonpath='{.data.admin-password}' | base64 -d`)
3. Cliquer sur **‚ò∞ (menu hamburger)** ‚Üí **Dashboards**
4. Chercher et ouvrir **"Falco Security Alerts"**

**Dashboard panels disponibles:**
- Panel 1: Taux d'alertes Falco (par seconde) - Graphique temporel
- Panel 2: Total alertes re√ßues - Compteur unique
- Panel 3: Alertes par destination (Elasticsearch, WebUI) - Pie chart
- Panel 4: Alertes Falco par priorit√© (Critical, Notice) - Graphique multi-s√©ries
- Panel 5: Top 5 r√®gles Falco - Table tri√©e
- Panel 6: Alertes par heure - Stat unique avec graphique

---

**Partie B: G√©n√©rer des alertes et observer les m√©triques**

**G√©n√©rer plusieurs alertes de test:**
```bash
# Test 1: Shell dans un conteneur
kubectl run grafana-test-1 --image=nginx
kubectl exec grafana-test-1 -- /bin/bash -c "ls /etc"
kubectl delete pod grafana-test-1

# Test 2: Modification de /etc
kubectl run grafana-test-2 --image=nginx
kubectl exec grafana-test-2 -- sh -c "echo test >> /etc/hosts"
kubectl delete pod grafana-test-2

# Test 3: Lecture de fichier sensible
kubectl run grafana-test-3 --image=nginx
kubectl exec grafana-test-3 -- cat /etc/shadow 2>/dev/null || true
kubectl delete pod grafana-test-3
```

**Observer les changements dans Grafana:**
1. Attendre 30 secondes (auto-refresh du dashboard)
2. Observer l'augmentation du "Taux d'alertes Falco"
3. V√©rifier l'incr√©mentation du "Total alertes re√ßues"
4. Observer la distribution dans "Alertes par destination"
5. V√©rifier que "Alertes par heure" augmente

---

**Partie C: V√©rifier les m√©triques dans Prometheus (optionnel)**

**Commandes:**
```bash
# Ouvrir Prometheus
kubectl port-forward -n security-siem svc/prometheus-kube-prometheus-prometheus 9090:9090
```

**V√©rification dans Prometheus:**
1. Ouvrir http://localhost:9090
2. Aller dans **Graph** ‚Üí **Query**
3. Tester les requ√™tes PromQL:

```promql
# Taux d'alertes par seconde
rate(falcosidekick_inputs[5m])

# Total d'alertes re√ßues
falcosidekick_inputs

# Alertes par destination
sum by (destination) (falcosidekick_outputs)

# Alertes Falco par priorit√©
sum by (priority) (falco_events)

# Top 5 r√®gles Falco
topk(5, sum by (rule) (falco_events))
```

4. Cliquer sur **Execute**
5. V√©rifier que les m√©triques retournent des valeurs

---

**R√©sultat attendu:**
- Dashboard Falco accessible dans Grafana
- M√©triques se mettent √† jour apr√®s g√©n√©ration d'alertes
- Graphiques montrent l'activit√© en temps r√©el
- Aucune erreur dans le panel "Taux d'erreurs"
- Latence Elasticsearch < 1 seconde

**Temps estim√©:** 5 minutes

**Note importante:**
- **Grafana** affiche des **m√©triques agr√©g√©es** (statistiques, tendances)
- Pour voir les **descriptions d√©taill√©es** des alertes, utiliser **Kibana** ou **Falcosidekick UI**
- Diff√©rence :
  - Grafana = Vue d'ensemble statistique (combien, quand, o√π)
  - Kibana = D√©tails complets (quoi, pourquoi, comment)
  - Falcosidekick UI = Temps r√©el (alertes individuelles)

**üìò Guide complet des dashboards : Voir [DASHBOARDS_GUIDE.md](./DASHBOARDS_GUIDE.md)**

---

### Test 3.5: Falco Tuning - R√©duction des faux positifs
**Objectif:** R√©duire le bruit des alertes en filtrant les namespaces de confiance (monitoring, syst√®me)

**Contexte:**
- Avant tuning : ~2000 alertes/h (beaucoup de bruit des outils de monitoring)
- Apr√®s tuning : ~50-100 alertes/h (uniquement alertes pertinentes)

**Commandes:**
```bash
# Ex√©cuter le script de tuning
./deploy/34-falco-tuning.sh

# Le script va :
# 1. Cr√©er des r√®gles Falco custom
# 2. Filtrer les namespaces de confiance :
#    - security-siem (Grafana, Prometheus, Elasticsearch, Kibana)
#    - trivy-system (scans de vuln√©rabilit√©s)
#    - kube-system (composants syst√®me, CNI)
#    - security-detection (Falco, Falcosidekick)
# 3. Red√©marrer Falco avec les nouvelles r√®gles

# R√©pondre 'y' quand demand√© pour appliquer la mise √† jour
```

**V√©rification apr√®s 5-10 minutes:**

1. **Dans Grafana** (Dashboard Falco Security Alerts):
   - Panel "Alertes par heure" devrait montrer ~50-100 au lieu de ~2000
   - Panel "Top 5 r√®gles Falco" devrait montrer principalement des r√®gles sur namespaces applicatifs

2. **Dans Kibana** (Discover ‚Üí Falco Alerts):
   ```
   # V√©rifier que les alertes syst√®me sont filtr√©es
   NOT k8s.ns.name: (kube-system OR security-siem OR trivy-system OR security-detection)
   ```
   - La plupart des alertes devraient √™tre sur namespaces applicatifs (`default`, vos apps)

3. **Tester avec un pod dans namespace par d√©faut** (devrait g√©n√©rer une alerte):
   ```bash
   kubectl run test-tuning --image=nginx -n default
   kubectl exec -n default test-tuning -- /bin/bash -c "ls /etc"
   kubectl delete pod test-tuning -n default
   ```
   - Cette alerte DOIT appara√Ætre dans Grafana/Kibana (namespace non filtr√©)

4. **Tester avec un pod dans namespace filtr√©** (ne devrait PAS g√©n√©rer d'alerte):
   ```bash
   kubectl run test-filtered --image=nginx -n security-siem
   kubectl exec -n security-siem test-filtered -- /bin/bash -c "ls /etc"
   kubectl delete pod test-filtered -n security-siem
   ```
   - Cette alerte NE DOIT PAS appara√Ætre (namespace filtr√©)

**R√©sultat attendu:**
- ‚úÖ Volume d'alertes r√©duit de ~95%
- ‚úÖ Alertes sur namespaces applicatifs toujours pr√©sentes
- ‚úÖ Alertes sur namespaces syst√®me/monitoring filtr√©es
- ‚úÖ Dashboard Grafana plus lisible avec des alertes pertinentes

**Temps estim√©:** 3-5 minutes

**Ajuster le tuning:**
```bash
# Pour ajouter d'autres namespaces √† filtrer
kubectl edit cm falco-rules-custom -n security-detection

# Ajouter votre namespace dans la liste trusted_namespaces
# Puis red√©marrer Falco
kubectl rollout restart daemonset falco -n security-detection
```

**üìò Pour comprendre comment interpr√©ter les alertes restantes : Voir [DASHBOARDS_GUIDE.md](./DASHBOARDS_GUIDE.md) section "Interpr√©tation des donn√©es"**

---

## 4. Tests Vault - PKI et Certificats

### Test 4.1: Cr√©ation automatique de certificat via cert-manager
**Objectif:** V√©rifier que cert-manager peut obtenir des certificats de Vault

**Commandes:**
```bash
# Cr√©er un certificat de test
cat <<EOF | kubectl apply -f -
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: demo-certificate
  namespace: default
spec:
  secretName: demo-tls
  issuerRef:
    name: vault-issuer
    kind: ClusterIssuer
  commonName: demo.example.com
  dnsNames:
  - demo.example.com
  - www.demo.example.com
EOF

# V√©rifier le statut
kubectl get certificate demo-certificate -n default
kubectl describe certificate demo-certificate -n default

# V√©rifier que le secret TLS est cr√©√©
kubectl get secret demo-tls -n default
```

**R√©sultat attendu:** Certificat cr√©√© avec statut "Ready: True"

**Temps estim√©:** 1 minute

**Cleanup:**
```bash
kubectl delete certificate demo-certificate -n default
kubectl delete secret demo-tls -n default
```

---

## 5. Tests Keycloak - IAM/SSO

### Test 5.1: Authentification via Keycloak
**Objectif:** V√©rifier que Keycloak fonctionne et peut authentifier les utilisateurs

**Commandes:**
```bash
# Port-forward Keycloak
kubectl port-forward -n security-iam svc/keycloak 8080:80
```

**V√©rification:**
1. Ouvrir http://localhost:8080
2. Login sur la console admin
3. Cr√©er un realm de test
4. Cr√©er un utilisateur de test
5. V√©rifier l'authentification

**Temps estim√©:** 3-5 minutes

---

### Test 5.2: Int√©gration OIDC (Option A ou B)
**Objectif:** Authentification Kubernetes via Keycloak OIDC

**Note:** √Ä d√©finir selon l'option choisie (Option A: kubelogin, Option B: gangway/dex)

**Temps estim√©:** TBD

---

## 6. Tests d'int√©gration

### Test 6.1: Visualisation compl√®te des donn√©es
**Objectif:** V√©rifier que toutes les sources de donn√©es sont visibles dans les dashboards

**V√©rifications:**
- [ ] Grafana affiche les m√©triques Prometheus de tous les services
- [ ] Grafana affiche les m√©triques Trivy
- [ ] Kibana affiche les rapports de vuln√©rabilit√©s Trivy
- [ ] Elasticsearch contient les donn√©es (v√©rifier le count)

**Commandes:**
```bash
# V√©rifier le nombre de documents dans Elasticsearch
ELASTIC_PASSWORD=$(kubectl get secret -n security-siem elasticsearch-master-credentials -o jsonpath='{.data.password}' | base64 -d)
kubectl exec -n security-siem elasticsearch-master-0 -- curl -k -s -u "elastic:$ELASTIC_PASSWORD" "https://localhost:9200/_cat/indices?v"
```

**Temps estim√©:** 5 minutes

---

### Test 6.2: Workflow complet de s√©curit√©
**Objectif:** D√©monstration bout en bout du workflow de s√©curit√©

**Sc√©nario:**
1. D√©ployer une application avec une image vuln√©rable
2. V√©rifier que Gatekeeper valide les policies
3. Trivy scanne et d√©tecte les vuln√©rabilit√©s
4. Visualiser dans Kibana les CVE d√©taill√©s
5. Visualiser dans Grafana les m√©triques agr√©g√©es
6. Falco d√©tecte des comportements runtime suspects
7. Corriger l'image et red√©ployer
8. V√©rifier que les vuln√©rabilit√©s diminuent

**Temps estim√©:** 10-15 minutes

---

## 7. Tests de haute disponibilit√©

### Test 7.1: R√©silience Vault
**Objectif:** V√©rifier que Vault en mode Raft survit √† la perte d'un pod

**Commandes:**
```bash
# V√©rifier l'√©tat initial
kubectl exec -n security-iam vault-0 -- vault status

# Supprimer un pod
kubectl delete pod -n security-iam vault-1 --force --grace-period=0

# V√©rifier que le cluster reste op√©rationnel
kubectl exec -n security-iam vault-0 -- vault status

# Attendre que le pod red√©marre
kubectl wait --for=condition=ready pod/vault-1 -n security-iam --timeout=120s
```

**R√©sultat attendu:** Cluster Vault reste op√©rationnel

**Temps estim√©:** 3 minutes

---

### Test 7.2: R√©silience Elasticsearch
**Objectif:** V√©rifier la r√©plication et disponibilit√©

**Commandes:**
```bash
# V√©rifier l'√©tat du cluster
ELASTIC_PASSWORD=$(kubectl get secret -n security-siem elasticsearch-master-credentials -o jsonpath='{.data.password}' | base64 -d)
kubectl exec -n security-siem elasticsearch-master-0 -- curl -k -s -u "elastic:$ELASTIC_PASSWORD" "https://localhost:9200/_cluster/health?pretty"

# Supprimer un pod
kubectl delete pod -n security-siem elasticsearch-master-1 --force --grace-period=0

# V√©rifier que le cluster reste green/yellow
kubectl exec -n security-siem elasticsearch-master-0 -- curl -k -s -u "elastic:$ELASTIC_PASSWORD" "https://localhost:9200/_cluster/health?pretty"
```

**R√©sultat attendu:** Cluster reste op√©rationnel (yellow acceptable temporairement)

**Temps estim√©:** 3 minutes

---

## 8. Tests de performance (optionnel)

### Test 8.1: Charge sur Trivy
**Objectif:** V√©rifier les performances de scan √† grande √©chelle

**Commandes:**
```bash
# D√©ployer plusieurs pods
for i in {1..10}; do
  kubectl run load-test-$i --image=nginx:1.21
done

# Attendre et v√©rifier les scans
sleep 300
kubectl get vulnerabilityreports -A | wc -l
```

**Temps estim√©:** 10 minutes

---

## Notes importantes

### Ordre des tests
1. Commencer par les tests unitaires (chaque service individuellement)
2. Puis les tests d'int√©gration
3. Finir par les tests de r√©silience

### Environnement
- Cluster Kind 4 n≈ìuds
- Windows 11 + Docker Desktop + WSL2 Ubuntu
- Tous les services d√©ploy√©s et op√©rationnels

### Cleanup g√©n√©ral apr√®s la d√©mo
```bash
# Supprimer tous les pods de test
kubectl delete pod -l demo=test --all-namespaces

# Supprimer tous les jobs de test
kubectl delete job -l demo=test --all-namespaces
```

---

## Checklist de pr√©paration

Avant de lancer la d√©mo, v√©rifier que :
- [ ] Tous les pods sont Running
- [ ] Elasticsearch est accessible et contient des donn√©es
- [ ] Kibana est accessible et le data view est cr√©√©
- [ ] Grafana est accessible avec les dashboards configur√©s
- [ ] Vault est initialis√© et unsealed
- [ ] Keycloak est accessible
- [ ] Falco est running sur tous les n≈ìuds
- [ ] Gatekeeper a des policies configur√©es
- [ ] Trivy Operator scanne activement
- [ ] Le CronJob d'export Trivy fonctionne

---

## Temps total estim√©
- Tests rapides (essentiels): ~30 minutes
- Tests complets: ~1-2 heures
- Avec troubleshooting: pr√©voir 3 heures

---

## Ressources utiles

### Port-forwards pour la d√©mo
```bash
# Grafana
kubectl port-forward -n monitoring svc/prometheus-grafana 3000:80

# Kibana
kubectl port-forward -n security-siem svc/kibana-kibana 5601:5601

# Vault
kubectl port-forward -n security-iam svc/vault 8200:8200

# Keycloak
kubectl port-forward -n security-iam svc/keycloak 8080:80

# Prometheus
kubectl port-forward -n monitoring svc/prometheus-kube-prometheus-prometheus 9090:9090
```

### Credentials
```bash
# Elasticsearch
kubectl get secret -n security-siem elasticsearch-master-credentials -o jsonpath='{.data.password}' | base64 -d

# Grafana
# User: admin
# Password: prom-operator

# Vault root token
kubectl get secret -n security-iam vault-init -o jsonpath='{.data.root-token}' | base64 -d
```
